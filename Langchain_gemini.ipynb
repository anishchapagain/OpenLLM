{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84d12ad1-b135-496f-be37-aa842b50a9e5",
   "metadata": {},
   "source": [
    "<h2>LangChain & Google Gemini API</h2>\n",
    "<h5><a href=\"https://ai.google.dev/\">Google AI for Developers</a> | <a href=\"https://api.python.langchain.com/en/latest/google_genai_api_reference.html\">LangChain Google</a></h5> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e556b9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API KEY using os.environ\n",
    "'''\n",
    "import os\n",
    "\n",
    "llm_key = 'GOOGLE_API_KEY' # OPENAI_API_KEY\n",
    "os.environ[llm_key] = '##' \n",
    "api_key = os.environ[llm_key]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bdcf8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read API KEY from file\n",
    "import json\n",
    "\n",
    "file_path = 'llms_vault.json'\n",
    "llm_key = 'GOOGLE_API_KEY'\n",
    "\n",
    "try:\n",
    "    with open(file_path,'r') as f:\n",
    "        api_key = json.loads(f.read()).get(llm_key)\n",
    "        if not api_key:\n",
    "            raise ValueError(f\"Some issue with '{llm_key}' from '{file_path}'. Verify the key:'{llm_key}' if it exists!\")\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"File related issue encountered, verify file path and name '{file_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb640c2e-747a-47b0-a526-75fd3b3cc432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(api_key) # api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32029c69",
   "metadata": {},
   "source": [
    "<h3>Using Gemini API</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6c15c48-c1bd-4435-92d2-85631aff98c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ai.google.dev/api\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=api_key) # genai.configure(api_key=os.environ[llm_key]) \n",
    "\n",
    "# list model names, requirement here is for content generation.\n",
    "models = [model for model in genai.list_models()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "673d241d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>description</th>\n",
       "      <th>supported_generation_methods</th>\n",
       "      <th>display_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>models/chat-bison-001</td>\n",
       "      <td>A legacy text-only model optimized for chat co...</td>\n",
       "      <td>[generateMessage, countMessageTokens]</td>\n",
       "      <td>PaLM 2 Chat (Legacy)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>models/text-bison-001</td>\n",
       "      <td>A legacy model that understands text and gener...</td>\n",
       "      <td>[generateText, countTextTokens, createTunedTex...</td>\n",
       "      <td>PaLM 2 (Legacy)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>models/embedding-gecko-001</td>\n",
       "      <td>Obtain a distributed representation of a text.</td>\n",
       "      <td>[embedText, countTextTokens]</td>\n",
       "      <td>Embedding Gecko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>models/gemini-1.0-pro</td>\n",
       "      <td>The best model for scaling across a wide range...</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>Gemini 1.0 Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>models/gemini-1.0-pro-001</td>\n",
       "      <td>The best model for scaling across a wide range...</td>\n",
       "      <td>[generateContent, countTokens, createTunedModel]</td>\n",
       "      <td>Gemini 1.0 Pro 001 (Tuning)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>models/gemini-1.0-pro-latest</td>\n",
       "      <td>The best model for scaling across a wide range...</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>Gemini 1.0 Pro Latest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>models/gemini-1.0-pro-vision-latest</td>\n",
       "      <td>The best image understanding model to handle a...</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>Gemini 1.0 Pro Vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>models/gemini-1.5-flash</td>\n",
       "      <td>Fast and versatile multimodal model for scalin...</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>Gemini 1.5 Flash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>models/gemini-1.5-flash-001</td>\n",
       "      <td>Fast and versatile multimodal model for scalin...</td>\n",
       "      <td>[generateContent, countTokens, createCachedCon...</td>\n",
       "      <td>Gemini 1.5 Flash 001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>models/gemini-1.5-flash-latest</td>\n",
       "      <td>Fast and versatile multimodal model for scalin...</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>Gemini 1.5 Flash Latest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>models/gemini-1.5-pro</td>\n",
       "      <td>Mid-size multimodal model that supports up to ...</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>Gemini 1.5 Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>models/gemini-1.5-pro-001</td>\n",
       "      <td>Mid-size multimodal model that supports up to ...</td>\n",
       "      <td>[generateContent, countTokens, createCachedCon...</td>\n",
       "      <td>Gemini 1.5 Pro 001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>models/gemini-1.5-pro-latest</td>\n",
       "      <td>Mid-size multimodal model that supports up to ...</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>Gemini 1.5 Pro Latest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>models/gemini-pro</td>\n",
       "      <td>The best model for scaling across a wide range...</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>Gemini 1.0 Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>models/gemini-pro-vision</td>\n",
       "      <td>The best image understanding model to handle a...</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>Gemini 1.0 Pro Vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>models/embedding-001</td>\n",
       "      <td>Obtain a distributed representation of a text.</td>\n",
       "      <td>[embedContent]</td>\n",
       "      <td>Embedding 001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>models/text-embedding-004</td>\n",
       "      <td>Obtain a distributed representation of a text.</td>\n",
       "      <td>[embedContent]</td>\n",
       "      <td>Text Embedding 004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>models/aqa</td>\n",
       "      <td>Model trained to return answers to questions t...</td>\n",
       "      <td>[generateAnswer]</td>\n",
       "      <td>Model that performs Attributed Question Answer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             model_name  \\\n",
       "0                 models/chat-bison-001   \n",
       "1                 models/text-bison-001   \n",
       "2            models/embedding-gecko-001   \n",
       "3                 models/gemini-1.0-pro   \n",
       "4             models/gemini-1.0-pro-001   \n",
       "5          models/gemini-1.0-pro-latest   \n",
       "6   models/gemini-1.0-pro-vision-latest   \n",
       "7               models/gemini-1.5-flash   \n",
       "8           models/gemini-1.5-flash-001   \n",
       "9        models/gemini-1.5-flash-latest   \n",
       "10                models/gemini-1.5-pro   \n",
       "11            models/gemini-1.5-pro-001   \n",
       "12         models/gemini-1.5-pro-latest   \n",
       "13                    models/gemini-pro   \n",
       "14             models/gemini-pro-vision   \n",
       "15                 models/embedding-001   \n",
       "16            models/text-embedding-004   \n",
       "17                           models/aqa   \n",
       "\n",
       "                                          description  \\\n",
       "0   A legacy text-only model optimized for chat co...   \n",
       "1   A legacy model that understands text and gener...   \n",
       "2      Obtain a distributed representation of a text.   \n",
       "3   The best model for scaling across a wide range...   \n",
       "4   The best model for scaling across a wide range...   \n",
       "5   The best model for scaling across a wide range...   \n",
       "6   The best image understanding model to handle a...   \n",
       "7   Fast and versatile multimodal model for scalin...   \n",
       "8   Fast and versatile multimodal model for scalin...   \n",
       "9   Fast and versatile multimodal model for scalin...   \n",
       "10  Mid-size multimodal model that supports up to ...   \n",
       "11  Mid-size multimodal model that supports up to ...   \n",
       "12  Mid-size multimodal model that supports up to ...   \n",
       "13  The best model for scaling across a wide range...   \n",
       "14  The best image understanding model to handle a...   \n",
       "15     Obtain a distributed representation of a text.   \n",
       "16     Obtain a distributed representation of a text.   \n",
       "17  Model trained to return answers to questions t...   \n",
       "\n",
       "                         supported_generation_methods  \\\n",
       "0               [generateMessage, countMessageTokens]   \n",
       "1   [generateText, countTextTokens, createTunedTex...   \n",
       "2                        [embedText, countTextTokens]   \n",
       "3                      [generateContent, countTokens]   \n",
       "4    [generateContent, countTokens, createTunedModel]   \n",
       "5                      [generateContent, countTokens]   \n",
       "6                      [generateContent, countTokens]   \n",
       "7                      [generateContent, countTokens]   \n",
       "8   [generateContent, countTokens, createCachedCon...   \n",
       "9                      [generateContent, countTokens]   \n",
       "10                     [generateContent, countTokens]   \n",
       "11  [generateContent, countTokens, createCachedCon...   \n",
       "12                     [generateContent, countTokens]   \n",
       "13                     [generateContent, countTokens]   \n",
       "14                     [generateContent, countTokens]   \n",
       "15                                     [embedContent]   \n",
       "16                                     [embedContent]   \n",
       "17                                   [generateAnswer]   \n",
       "\n",
       "                                         display_name  \n",
       "0                                PaLM 2 Chat (Legacy)  \n",
       "1                                     PaLM 2 (Legacy)  \n",
       "2                                     Embedding Gecko  \n",
       "3                                      Gemini 1.0 Pro  \n",
       "4                         Gemini 1.0 Pro 001 (Tuning)  \n",
       "5                               Gemini 1.0 Pro Latest  \n",
       "6                               Gemini 1.0 Pro Vision  \n",
       "7                                    Gemini 1.5 Flash  \n",
       "8                                Gemini 1.5 Flash 001  \n",
       "9                             Gemini 1.5 Flash Latest  \n",
       "10                                     Gemini 1.5 Pro  \n",
       "11                                 Gemini 1.5 Pro 001  \n",
       "12                              Gemini 1.5 Pro Latest  \n",
       "13                                     Gemini 1.0 Pro  \n",
       "14                              Gemini 1.0 Pro Vision  \n",
       "15                                      Embedding 001  \n",
       "16                                 Text Embedding 004  \n",
       "17  Model that performs Attributed Question Answer...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# convert models to pandas dataframe.\n",
    "df = pd.DataFrame(models, columns=['name', 'description', 'supported_generation_methods', 'display_name'])\n",
    "df.rename(columns={'name': 'model_name'}, inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "00ed2188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>display_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>models/gemini-1.0-pro</td>\n",
       "      <td>Gemini 1.0 Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>models/gemini-1.0-pro-001</td>\n",
       "      <td>Gemini 1.0 Pro 001 (Tuning)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>models/gemini-1.0-pro-latest</td>\n",
       "      <td>Gemini 1.0 Pro Latest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>models/gemini-1.0-pro-vision-latest</td>\n",
       "      <td>Gemini 1.0 Pro Vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>models/gemini-1.5-flash</td>\n",
       "      <td>Gemini 1.5 Flash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>models/gemini-1.5-flash-001</td>\n",
       "      <td>Gemini 1.5 Flash 001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>models/gemini-1.5-flash-latest</td>\n",
       "      <td>Gemini 1.5 Flash Latest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>models/gemini-1.5-pro</td>\n",
       "      <td>Gemini 1.5 Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>models/gemini-1.5-pro-001</td>\n",
       "      <td>Gemini 1.5 Pro 001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>models/gemini-1.5-pro-latest</td>\n",
       "      <td>Gemini 1.5 Pro Latest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>models/gemini-pro</td>\n",
       "      <td>Gemini 1.0 Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>models/gemini-pro-vision</td>\n",
       "      <td>Gemini 1.0 Pro Vision</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             model_name                 display_name\n",
       "3                 models/gemini-1.0-pro               Gemini 1.0 Pro\n",
       "4             models/gemini-1.0-pro-001  Gemini 1.0 Pro 001 (Tuning)\n",
       "5          models/gemini-1.0-pro-latest        Gemini 1.0 Pro Latest\n",
       "6   models/gemini-1.0-pro-vision-latest        Gemini 1.0 Pro Vision\n",
       "7               models/gemini-1.5-flash             Gemini 1.5 Flash\n",
       "8           models/gemini-1.5-flash-001         Gemini 1.5 Flash 001\n",
       "9        models/gemini-1.5-flash-latest      Gemini 1.5 Flash Latest\n",
       "10                models/gemini-1.5-pro               Gemini 1.5 Pro\n",
       "11            models/gemini-1.5-pro-001           Gemini 1.5 Pro 001\n",
       "12         models/gemini-1.5-pro-latest        Gemini 1.5 Pro Latest\n",
       "13                    models/gemini-pro               Gemini 1.0 Pro\n",
       "14             models/gemini-pro-vision        Gemini 1.0 Pro Vision"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter out the 'supported_generation_methods' that contains 'generateContent' only.\n",
    "\n",
    "content_df = df[df['supported_generation_methods'].apply(lambda x: 'generateContent' in x)]\n",
    "content_df[['model_name','display_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8637035b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/gemini-1.0-pro',\n",
       " 'models/gemini-1.5-flash',\n",
       " 'models/gemini-1.5-pro',\n",
       " 'models/gemini-1.5-pro-latest']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting few random models name. \n",
    "selected_models = []\n",
    "selected_models.extend(content_df.loc[[3,7,10,12]]['model_name']) \n",
    "selected_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cfcac630",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(model_name=selected_models[0]) # choosing model, can also remove the text 'models/' from model text.\n",
    "prompts = [\"list the colors seen in the rainbow with words in capital\"] # issuing prompt for model chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b9677431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"* RED\\n* ORANGE\\n* YELLOW\\n* GREEN\\n* BLUE\\n* INDIGO\\n* VIOLET\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 12,\n",
       "        \"candidates_token_count\": 23,\n",
       "        \"total_token_count\": 35\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://ai.google.dev/api/python/google/generativeai/GenerativeModel#generate_content\n",
    "response = model.generate_content(prompts) \n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "27477c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* RED\n",
      "* ORANGE\n",
      "* YELLOW\n",
      "* GREEN\n",
      "* BLUE\n",
      "* INDIGO\n",
      "* VIOLET\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbd0e5d",
   "metadata": {},
   "source": [
    "Using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56744aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbb1485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7805c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    google_api_key = api_key,\n",
    "    model='gemini-1.5-pro',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653bd925",
   "metadata": {},
   "outputs": [],
   "source": [
    "gem_response = llm.invoke(\"list the colors seen in the rainbow with words in capital\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01bd66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gem_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82844b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "gem_response.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
